{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    IS_COLAB = True\n",
    "except Exception:\n",
    "    IS_COLAB = False\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "if not tf.test.is_gpu_available():\n",
    "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_sample_image\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"cnn\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image):\n",
    "    plt.imshow(image, cmap=\"gray\", interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def plot_color_image(image):\n",
    "    plt.imshow(image, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like we're going to use `Xception` model. Let's start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split, valid_split, train_split = tfds.Split.TRAIN.subsplit([10, 15, 75])\n",
    "\n",
    "test_set_raw = tfds.load(\"tf_flowers\", split=test_split, as_supervised=True)\n",
    "valid_set_raw = tfds.load(\"tf_flowers\", split=valid_split, as_supervised=True)\n",
    "train_set_raw = tfds.load(\"tf_flowers\", split=train_split, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label):\n",
    "    resized_image = tf.image.resize(image, [224, 224])\n",
    "    final_image = keras.applications.xception.preprocess_input(resized_image)\n",
    "    return final_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def central_crop(image):\n",
    "    shape = tf.shape(image)\n",
    "    min_dim = tf.reduce_min([shape[0], shape[1]])\n",
    "    top_crop = (shape[0] - min_dim) // 4\n",
    "    bottom_crop = shape[0] - top_crop\n",
    "    left_crop = (shape[1] - min_dim) // 4\n",
    "    right_crop = shape[1] - left_crop\n",
    "    return image[top_crop:bottom_crop, left_crop:right_crop]\n",
    "\n",
    "def random_crop(image):\n",
    "    shape = tf.shape(image)\n",
    "    min_dim = tf.reduce_min([shape[0], shape[1]]) * 90 // 100\n",
    "    return tf.image.random_crop(image, [min_dim, min_dim, 3])\n",
    "\n",
    "def preprocess(image, label, randomize=False):\n",
    "    if randomize:\n",
    "        cropped_image = random_crop(image)\n",
    "        cropped_image = tf.image.random_flip_left_right(cropped_image)\n",
    "    else:\n",
    "        cropped_image = central_crop(image)\n",
    "    resized_image = tf.image.resize(cropped_image, [224, 224])\n",
    "    final_image = keras.applications.xception.preprocess_input(resized_image)\n",
    "    return final_image, label\n",
    "\n",
    "batch_size = 32\n",
    "train_set = train_set_raw.shuffle(1000).repeat()\n",
    "train_set = train_set.map(partial(preprocess, randomize=True)).batch(batch_size).prefetch(1)\n",
    "valid_set = valid_set_raw.map(preprocess).batch(batch_size).prefetch(1)\n",
    "test_set = test_set_raw.map(preprocess).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, info = tfds.load(\"tf_flowers\", as_supervised=True, with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = info.features[\"label\"].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = info.splits[\"train\"].num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3670"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.xception.Xception(weights=\"imagenet\",\n",
    "                                                  include_top=False)\n",
    "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = keras.layers.Dense(n_classes, activation=\"softmax\")(avg)\n",
    "model = keras.models.Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.2, momentum=0.9, decay=0.01)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_set,\n",
    "                    steps_per_epoch=int(0.75 * dataset_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(0.15 * dataset_size / batch_size),\n",
    "                    epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9,\n",
    "                                 nesterov=True, decay=0.001)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set,\n",
    "                    steps_per_epoch=int(0.75 * dataset_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(0.15 * dataset_size / batch_size),\n",
    "                    epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to use resnet. That's not easy - we don't know the correct learning rate and we get really low `val_accuracy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lr finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_resnet(lr=.2, epochs=2):\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    base_model_resnet = tf.keras.applications.ResNet101V2(weights=\"imagenet\",\n",
    "                                                              include_top=False)\n",
    "    avg = tf.keras.layers.GlobalAveragePooling2D()(base_model_resnet.output)\n",
    "    output = tf.keras.layers.Dense(n_classes, activation=\"softmax\")(avg)\n",
    "    model_resnet = tf.keras.models.Model(inputs=base_model_resnet.input, outputs=output)\n",
    "    \n",
    "    for layer in base_model_resnet.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.SGD(lr=lr, momentum=0.9, decay=0.01)\n",
    "#     optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    model_resnet.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "    \n",
    "    history_resnet = model_resnet.fit(train_set,\n",
    "                    steps_per_epoch=int(0.75 * dataset_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(0.15 * dataset_size / batch_size),\n",
    "                    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates = [.1, .05, .001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr=0.1\n",
      "Train for 86 steps, validate for 17 steps\n",
      "Epoch 1/3\n",
      "86/86 [==============================] - 24s 284ms/step - loss: 1.9534 - accuracy: 0.7613 - val_loss: 7.4733 - val_accuracy: 0.6581\n",
      "Epoch 2/3\n",
      "86/86 [==============================] - 17s 202ms/step - loss: 1.1915 - accuracy: 0.8605 - val_loss: 5.1221 - val_accuracy: 0.7059\n",
      "Epoch 3/3\n",
      "86/86 [==============================] - 18s 206ms/step - loss: 0.7635 - accuracy: 0.8859 - val_loss: 4.9482 - val_accuracy: 0.7096\n",
      "lr=0.05\n",
      "Train for 86 steps, validate for 17 steps\n",
      "Epoch 1/3\n",
      "86/86 [==============================] - 25s 293ms/step - loss: 0.9091 - accuracy: 0.7852 - val_loss: 3.9208 - val_accuracy: 0.6673\n",
      "Epoch 2/3\n",
      "86/86 [==============================] - 18s 208ms/step - loss: 0.4961 - accuracy: 0.8710 - val_loss: 3.2275 - val_accuracy: 0.6783\n",
      "Epoch 3/3\n",
      "86/86 [==============================] - 18s 215ms/step - loss: 0.4262 - accuracy: 0.8924 - val_loss: 2.9868 - val_accuracy: 0.6838\n",
      "lr=0.001\n",
      "Train for 86 steps, validate for 17 steps\n",
      "Epoch 1/3\n",
      "86/86 [==============================] - 27s 309ms/step - loss: 1.0603 - accuracy: 0.6086 - val_loss: 1.1933 - val_accuracy: 0.5919\n",
      "Epoch 2/3\n",
      "86/86 [==============================] - 18s 214ms/step - loss: 0.6201 - accuracy: 0.7929 - val_loss: 1.1893 - val_accuracy: 0.6195\n",
      "Epoch 3/3\n",
      "86/86 [==============================] - 18s 215ms/step - loss: 0.5475 - accuracy: 0.8176 - val_loss: 1.2408 - val_accuracy: 0.6268\n"
     ]
    }
   ],
   "source": [
    "for lr in rates:\n",
    "    print(f'lr={lr}')\n",
    "    train_resnet(lr=lr, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "base_model_resnet = tf.keras.applications.ResNet101V2(weights=\"imagenet\",\n",
    "                                                              include_top=False)\n",
    "avg = tf.keras.layers.GlobalAveragePooling2D()(base_model_resnet.output)\n",
    "output = tf.keras.layers.Dense(n_classes, activation=\"softmax\")(avg)\n",
    "model_resnet = tf.keras.models.Model(inputs=base_model_resnet.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model_resnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(lr=0.09, momentum=0.9, decay=0.01)\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=.007)\n",
    "model_resnet.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 86 steps, validate for 17 steps\n",
      "Epoch 1/5\n",
      "86/86 [==============================] - 26s 306ms/step - loss: 1.4257 - accuracy: 0.7740 - val_loss: 6.1327 - val_accuracy: 0.6875\n",
      "Epoch 2/5\n",
      "86/86 [==============================] - 19s 222ms/step - loss: 0.9116 - accuracy: 0.8579 - val_loss: 4.9151 - val_accuracy: 0.6728\n",
      "Epoch 3/5\n",
      "86/86 [==============================] - 19s 218ms/step - loss: 0.6592 - accuracy: 0.8888 - val_loss: 3.8833 - val_accuracy: 0.7647\n",
      "Epoch 4/5\n",
      "86/86 [==============================] - 18s 210ms/step - loss: 0.4408 - accuracy: 0.9157 - val_loss: 3.7745 - val_accuracy: 0.7482\n",
      "Epoch 5/5\n",
      "86/86 [==============================] - 18s 209ms/step - loss: 0.4263 - accuracy: 0.9110 - val_loss: 3.3897 - val_accuracy: 0.7647\n"
     ]
    }
   ],
   "source": [
    "history_resnet = model_resnet.fit(train_set,\n",
    "                    steps_per_epoch=int(0.75 * dataset_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(0.15 * dataset_size / batch_size),\n",
    "                    epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 86 steps, validate for 17 steps\n",
      "Epoch 1/10\n",
      "86/86 [==============================] - 63s 730ms/step - loss: 1.0866 - accuracy: 0.6853 - val_loss: 6.7450 - val_accuracy: 0.3493\n",
      "Epoch 2/10\n",
      "86/86 [==============================] - 47s 542ms/step - loss: 0.6007 - accuracy: 0.7994 - val_loss: 1.0123 - val_accuracy: 0.7408\n",
      "Epoch 3/10\n",
      "86/86 [==============================] - 48s 554ms/step - loss: 0.3685 - accuracy: 0.8586 - val_loss: 0.6103 - val_accuracy: 0.8180\n",
      "Epoch 4/10\n",
      "86/86 [==============================] - 47s 546ms/step - loss: 0.2885 - accuracy: 0.8968 - val_loss: 0.4172 - val_accuracy: 0.8529\n",
      "Epoch 5/10\n",
      "86/86 [==============================] - 47s 547ms/step - loss: 0.2300 - accuracy: 0.9179 - val_loss: 0.3621 - val_accuracy: 0.8529\n",
      "Epoch 6/10\n",
      "86/86 [==============================] - 47s 547ms/step - loss: 0.1846 - accuracy: 0.9371 - val_loss: 0.3030 - val_accuracy: 0.8860\n",
      "Epoch 7/10\n",
      "86/86 [==============================] - 47s 547ms/step - loss: 0.1463 - accuracy: 0.9477 - val_loss: 0.3289 - val_accuracy: 0.9007\n",
      "Epoch 8/10\n",
      "86/86 [==============================] - 47s 548ms/step - loss: 0.1336 - accuracy: 0.9535 - val_loss: 0.3197 - val_accuracy: 0.8952\n",
      "Epoch 9/10\n",
      "86/86 [==============================] - 47s 549ms/step - loss: 0.1083 - accuracy: 0.9597 - val_loss: 0.3325 - val_accuracy: 0.8750\n",
      "Epoch 10/10\n",
      "86/86 [==============================] - 47s 548ms/step - loss: 0.0846 - accuracy: 0.9749 - val_loss: 0.4089 - val_accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "for layer in base_model_resnet.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.005, momentum=0.9,\n",
    "                                 nesterov=True, decay=0.0005)\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=.007/10)\n",
    "model_resnet.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model_resnet.fit(train_set,\n",
    "                    steps_per_epoch=int(0.75 * dataset_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(0.15 * dataset_size / batch_size),\n",
    "                    epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
