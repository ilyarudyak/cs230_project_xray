{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on this [notebook](https://www.kaggle.com/aakashnain/beating-everything-with-depthwise-convolution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import shutil\n",
    "import imgaug as aug\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mimg\n",
    "import imgaug.augmenters as iaa\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, SeparableConv2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for hash based operations in python\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# Set the numpy seed\n",
    "np.random.seed(111)\n",
    "\n",
    "# Set the random seed in tensorflow at graph level\n",
    "tf.random.set_seed(111)\n",
    "\n",
    "# Make the augmentation sequence deterministic\n",
    "aug.seed(111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.home() / 'data/chest_xray/small_10'\n",
    "\n",
    "# Path to train directory (Fancy pathlib...no more os.path!!)\n",
    "train_dir = data_dir / 'train'\n",
    "\n",
    "# Path to validation directory\n",
    "val_dir = data_dir / 'val'\n",
    "\n",
    "# Path to test directory\n",
    "test_dir = data_dir / 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path to the normal and pneumonia sub-directories\n",
    "normal_cases_dir = train_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = train_dir / 'PNEUMONIA'\n",
    "\n",
    "# Get the list of all the images\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "# An empty list. We will insert the data into this list in (img_path, label) format\n",
    "train_data = []\n",
    "\n",
    "# Go through all the normal cases. The label for these cases will be 0\n",
    "for img in normal_cases:\n",
    "    train_data.append((img,0))\n",
    "\n",
    "# Go through all the pneumonia cases. The label for these cases will be 1\n",
    "for img in pneumonia_cases:\n",
    "    train_data.append((img, 1))\n",
    "\n",
    "# Get a pandas dataframe from the data we have in our list \n",
    "train_data = pd.DataFrame(train_data, columns=['image', 'label'],index=None)\n",
    "\n",
    "# Shuffle the data \n",
    "train_data = train_data.sample(frac=1.).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/ilyarudyak/data/chest_xray/small_10/tra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/ilyarudyak/data/chest_xray/small_10/tra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/ilyarudyak/data/chest_xray/small_10/tra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/ilyarudyak/data/chest_xray/small_10/tra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/ilyarudyak/data/chest_xray/small_10/tra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  label\n",
       "0  /Users/ilyarudyak/data/chest_xray/small_10/tra...      0\n",
       "1  /Users/ilyarudyak/data/chest_xray/small_10/tra...      0\n",
       "2  /Users/ilyarudyak/data/chest_xray/small_10/tra...      1\n",
       "3  /Users/ilyarudyak/data/chest_xray/small_10/tra...      0\n",
       "4  /Users/ilyarudyak/data/chest_xray/small_10/tra...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    64\n",
       "0    64\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path to the sub-directories\n",
    "normal_cases_dir = val_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = val_dir / 'PNEUMONIA'\n",
    "\n",
    "# Get the list of all the images\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "# List that are going to contain validation images data and the corresponding labels\n",
    "valid_data = []\n",
    "valid_labels = []\n",
    "\n",
    "\n",
    "# Some images are in grayscale while majority of them contains 3 channels. So, if the image is grayscale, we will convert into a image with 3 channels.\n",
    "# We will normalize the pixel values and resizing all the images to 224x224 \n",
    "\n",
    "# Normal cases\n",
    "for img in normal_cases:\n",
    "    img = cv2.imread(str(img))\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    if img.shape[2] ==1:\n",
    "        img = np.dstack([img, img, img])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32)/255.\n",
    "    label = tf.keras.utils.to_categorical(0, num_classes=2)\n",
    "    valid_data.append(img)\n",
    "    valid_labels.append(label)\n",
    "                      \n",
    "# Pneumonia cases        \n",
    "for img in pneumonia_cases:\n",
    "    img = cv2.imread(str(img))\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    if img.shape[2] ==1:\n",
    "        img = np.dstack([img, img, img])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32)/255.\n",
    "    label = tf.keras.utils.to_categorical(1, num_classes=2)\n",
    "    valid_data.append(img)\n",
    "    valid_labels.append(label)\n",
    "    \n",
    "# Convert the list into numpy arrays\n",
    "valid_data = np.array(valid_data)\n",
    "valid_labels = np.array(valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 224, 224, 3), (20, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data.shape, valid_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = iaa.OneOf([\n",
    "    iaa.Fliplr(), # horizontal flips\n",
    "    iaa.Affine(rotate=20), # roatation\n",
    "    iaa.Multiply((1.2, 1.5))]) #random brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(data, batch_size):\n",
    "    # Get total number of samples in the data\n",
    "    n = len(data)\n",
    "    steps = n//batch_size\n",
    "    \n",
    "    # Define two numpy arrays for containing batch data and labels\n",
    "    batch_data = np.zeros((batch_size, 224, 224, 3), dtype=np.float32)\n",
    "    batch_labels = np.zeros((batch_size,2), dtype=np.float32)\n",
    "\n",
    "    # Get a numpy array of all the indices of the input data\n",
    "    indices = np.arange(n)\n",
    "    \n",
    "    # Initialize a counter\n",
    "    i =0\n",
    "    while True:\n",
    "        np.random.shuffle(indices)\n",
    "        # Get the next batch \n",
    "        count = 0\n",
    "        next_batch = indices[(i*batch_size):(i+1)*batch_size]\n",
    "        for j, idx in enumerate(next_batch):\n",
    "            img_name = data.iloc[idx]['image']\n",
    "            label = data.iloc[idx]['label']\n",
    "            \n",
    "            # one hot encoding\n",
    "            encoded_label = tf.keras.utils.to_categorical(label, num_classes=2)\n",
    "            # read the image and resize\n",
    "            img = cv2.imread(str(img_name))\n",
    "            img = cv2.resize(img, (224,224))\n",
    "            \n",
    "            # check if it's grayscale\n",
    "            if img.shape[2]==1:\n",
    "                img = np.dstack([img, img, img])\n",
    "            \n",
    "            # cv2 reads in BGR mode by default\n",
    "            orig_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            # normalize the image pixels\n",
    "            orig_img = img.astype(np.float32)/255.\n",
    "            \n",
    "            batch_data[count] = orig_img\n",
    "            batch_labels[count] = encoded_label\n",
    "            \n",
    "            # generating more samples of the undersampled class\n",
    "            if label==0 and count < batch_size-2:\n",
    "                aug_img1 = seq.augment_image(img)\n",
    "                aug_img2 = seq.augment_image(img)\n",
    "                aug_img1 = cv2.cvtColor(aug_img1, cv2.COLOR_BGR2RGB)\n",
    "                aug_img2 = cv2.cvtColor(aug_img2, cv2.COLOR_BGR2RGB)\n",
    "                aug_img1 = aug_img1.astype(np.float32)/255.\n",
    "                aug_img2 = aug_img2.astype(np.float32)/255.\n",
    "\n",
    "                batch_data[count+1] = aug_img1\n",
    "                batch_labels[count+1] = encoded_label\n",
    "                batch_data[count+2] = aug_img2\n",
    "                batch_labels[count+2] = encoded_label\n",
    "                count +=2\n",
    "            \n",
    "            else:\n",
    "                count+=1\n",
    "            \n",
    "            if count==batch_size-1:\n",
    "                break\n",
    "            \n",
    "        i+=1\n",
    "        yield batch_data, batch_labels\n",
    "            \n",
    "        if i>=steps:\n",
    "            i=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input_img = Input(shape=(224,224,3), name='ImageInput')\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_1')(input_img)\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool1')(x)\n",
    "    \n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_1')(x)\n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool2')(x)\n",
    "    \n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_1')(x)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_2')(x)\n",
    "    x = BatchNormalization(name='bn2')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool3')(x)\n",
    "    \n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_1')(x)\n",
    "    x = BatchNormalization(name='bn3')(x)\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_2')(x)\n",
    "    x = BatchNormalization(name='bn4')(x)\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool4')(x)\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(0.5, name='dropout1')(x)\n",
    "    x = Dense(512, activation='relu', name='fc2')(x)\n",
    "    x = Dropout(0.5, name='dropout2')(x)\n",
    "    x = Dense(2, activation='softmax', name='fc3')(x)\n",
    "    \n",
    "    model = Model(inputs=input_img, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "ImageInput (InputLayer)      [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "Conv1_1 (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "Conv1_2 (Conv2D)             (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "Conv2_1 (SeparableConv2D)    (None, 112, 112, 128)     8896      \n",
      "_________________________________________________________________\n",
      "Conv2_2 (SeparableConv2D)    (None, 112, 112, 128)     17664     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "Conv3_1 (SeparableConv2D)    (None, 56, 56, 256)       34176     \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "Conv3_2 (SeparableConv2D)    (None, 56, 56, 256)       68096     \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "Conv3_3 (SeparableConv2D)    (None, 56, 56, 256)       68096     \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "Conv4_1 (SeparableConv2D)    (None, 28, 28, 512)       133888    \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "Conv4_2 (SeparableConv2D)    (None, 28, 28, 512)       267264    \n",
      "_________________________________________________________________\n",
      "bn4 (BatchNormalization)     (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "Conv4_3 (SeparableConv2D)    (None, 28, 28, 512)       267264    \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              102761472 \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 104,197,506\n",
      "Trainable params: 104,194,434\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model =  build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_path = Path.home() / 'data/chest_xray/vgg-16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ilyarudyak/data/chest_xray/vgg-16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the VGG16 weight file\n",
    "\n",
    "f = h5py.File(str(vgg_path), 'r')\n",
    "\n",
    "# Select the layers for which you want to set weight.\n",
    "\n",
    "w,b = f['block1_conv1']['block1_conv1_W_1:0'], f['block1_conv1']['block1_conv1_b_1:0']\n",
    "model.layers[1].set_weights = [w,b]\n",
    "\n",
    "w,b = f['block1_conv2']['block1_conv2_W_1:0'], f['block1_conv2']['block1_conv2_b_1:0']\n",
    "model.layers[2].set_weights = [w,b]\n",
    "\n",
    "w,b = f['block2_conv1']['block2_conv1_W_1:0'], f['block2_conv1']['block2_conv1_b_1:0']\n",
    "model.layers[4].set_weights = [w,b]\n",
    "\n",
    "w,b = f['block2_conv2']['block2_conv2_W_1:0'], f['block2_conv2']['block2_conv2_b_1:0']\n",
    "model.layers[5].set_weights = [w,b]\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "ImageInput (InputLayer)      [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "Conv1_1 (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "Conv1_2 (Conv2D)             (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "Conv2_1 (SeparableConv2D)    (None, 112, 112, 128)     8896      \n",
      "_________________________________________________________________\n",
      "Conv2_2 (SeparableConv2D)    (None, 112, 112, 128)     17664     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "Conv3_1 (SeparableConv2D)    (None, 56, 56, 256)       34176     \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "Conv3_2 (SeparableConv2D)    (None, 56, 56, 256)       68096     \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "Conv3_3 (SeparableConv2D)    (None, 56, 56, 256)       68096     \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "Conv4_1 (SeparableConv2D)    (None, 28, 28, 512)       133888    \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "Conv4_2 (SeparableConv2D)    (None, 28, 28, 512)       267264    \n",
      "_________________________________________________________________\n",
      "bn4 (BatchNormalization)     (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "Conv4_3 (SeparableConv2D)    (None, 28, 28, 512)       267264    \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              102761472 \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 104,197,506\n",
      "Trainable params: 104,194,434\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.0001, decay=1e-5)\n",
    "es = EarlyStopping(patience=5)\n",
    "\n",
    "filepath = Path.home() / 'data/chest_xray/models/best_model'\n",
    "chkpt = ModelCheckpoint(filepath=str(filepath), save_best_only=True, save_weights_only=True)\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'],optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training and validation steps: 32 and 20\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "nb_epochs = 1\n",
    "\n",
    "# Get a train data generator\n",
    "train_data_gen = data_gen(data=train_data, batch_size=batch_size)\n",
    "\n",
    "# Define the number of training steps\n",
    "nb_train_steps = train_data.shape[0]//batch_size\n",
    "\n",
    "print(\"Number of training and validation steps: {} and {}\".format(nb_train_steps, len(valid_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 114s 4s/step - loss: 0.5320 - accuracy: 0.6406 - val_loss: 0.7099 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit_generator(train_data_gen, \n",
    "                              epochs=nb_epochs, \n",
    "                              steps_per_epoch=nb_train_steps,\n",
    "                              validation_data=(valid_data, valid_labels),\n",
    "                              callbacks=[es, chkpt],\n",
    "                              class_weight={0:1.0, 1:0.4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model weights\n",
    "# model.load_weights(str(best_model_filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test examples:  (16, 224, 224, 3)\n",
      "Total number of labels: (16, 2)\n"
     ]
    }
   ],
   "source": [
    "# Preparing test data\n",
    "normal_cases_dir = test_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = test_dir / 'PNEUMONIA'\n",
    "\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "for img in normal_cases:\n",
    "    img = cv2.imread(str(img))\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    if img.shape[2] ==1:\n",
    "        img = np.dstack([img, img, img])\n",
    "    else:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32)/255.\n",
    "    label = tf.keras.utils.to_categorical(0, num_classes=2)\n",
    "    test_data.append(img)\n",
    "    test_labels.append(label)\n",
    "                      \n",
    "for img in pneumonia_cases:\n",
    "    img = cv2.imread(str(img))\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    if img.shape[2] ==1:\n",
    "        img = np.dstack([img, img, img])\n",
    "    else:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32)/255.\n",
    "    label = tf.keras.utils.to_categorical(1, num_classes=2)\n",
    "    test_data.append(img)\n",
    "    test_labels.append(label)\n",
    "    \n",
    "\n",
    "test_data = np.array(test_data)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print(\"Total number of test examples: \", test_data.shape)\n",
    "print(\"Total number of labels:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 190ms/sample - loss: 0.7099 - accuracy: 0.5000\n",
      "Loss on test set:  0.7099227905273438\n",
      "Accuracy on test set:  0.5\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_score = model.evaluate(test_data, test_labels, batch_size=16)\n",
    "print(\"Loss on test set: \", test_loss)\n",
    "print(\"Accuracy on test set: \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16,)\n",
      "(16,)\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(test_data, batch_size=16)\n",
    "preds = np.argmax(preds, axis=-1)\n",
    "\n",
    "# Original labels\n",
    "orig_test_labels = np.argmax(test_labels, axis=-1)\n",
    "\n",
    "print(orig_test_labels.shape)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm  = confusion_matrix(orig_test_labels, preds)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True, cmap=plt.cm.Blues)\n",
    "plt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "plt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of the model is 0.00\n",
      "Precision of the model is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Calculate Precision and Recall\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "\n",
    "print(\"Recall of the model is {:.2f}\".format(recall))\n",
    "print(\"Precision of the model is {:.2f}\".format(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
